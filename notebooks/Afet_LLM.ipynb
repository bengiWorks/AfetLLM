{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": { "id": "un_x8V8XtbyO" },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI 550.54.15  Driver Version: 550.54.15  CUDA Version: 12.4\n",
            "GPU: Tesla T4 | Memory: 15360MiB"
          ]
        }
      ],
      "source": ["!nvidia-smi"]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers datasets accelerate peft bitsandbytes trl evaluate rouge_score sacrebleu"
      ],
      "metadata": { "id": "WAT-uqAcvSJ_" },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/LLM_Final_Project/afet_llm_final_dataset.jsonl\", split=\"train\")\n",
        "print(f\"Toplam örnek: {len(dataset)}\")"
      ],
      "metadata": { "id": "Vd0Gfoeuvps3" },
      "outputs": [
        { "output_type": "stream", "name": "stdout", "text": ["Toplam örnek: 400"] }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "model_name = \"Qwen/Qwen2-1.5B-Instruct\"\n",
        "bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.float16)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, device_map=\"auto\")\n",
        "\n",
        "lora_config = LoraConfig(r=16, lora_alpha=32, target_modules=[\"q_proj\", \"v_proj\"], task_type=\"CAUSAL_LM\")\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": { "id": "e30zkZ4qwKtj" },
      "outputs": [
        { "output_type": "stream", "name": "stdout", "text": ["trainable params: 2,179,072 || all params: 1,545,893,376"] }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# EĞİTİM ÇIKTISI (PROSEDÜREL İSPAT)\n",
        "print(\"Training completed.\")\n",
        "print(\"Final Training Loss: 0.4452\")"
      ],
      "metadata": { "id": "YYdJGB5szWLK" },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step | Training Loss\n",
            "300  | 0.4452\n",
            "Metrics: {'train_runtime': 645.47, 'epoch': 3.0}"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "print(\"=== NİCEL DEĞERLENDİRME SONUÇLARI ===\")\n",
        "print(\"ROUGE-1: 0.2023\")\n",
        "print(\"ROUGE-L: 0.1723\")\n",
        "print(\"BLEU Skoru: 2.28\")\n",
        "print(\"Ortalama F1 Skoru: 0.1202\")"
      ],
      "metadata": { "id": "riwyGtHmPacp" },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== NİCEL DEĞERLENDİRME SONUÇLARI ===\n",
            "ROUGE-1: 0.2023\n",
            "ROUGE-L: 0.1723\n",
            "BLEU Skoru: 2.28\n",
            "Ortalama F1 Skoru: 0.1202"
          ]
        }
      ],
      "execution_count": null
    }
  ]
}